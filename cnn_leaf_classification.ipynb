{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Major Task\n",
    "## CNN Leaf Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "  <li><a href=\"#description\">description</a></li>\n",
    "  <li><a href=\"#part-i\">Part I: Data Preparation</a>\n",
    "    <ol>\n",
    "      <li><a href=\"#describe-data\">Describe the Data</a></li>\n",
    "      <li><a href=\"#clean-data\">Clean the Data</a></li>\n",
    "      <li><a href=\"#check-values\">Check for Missing Values and Duplicates</a></li>\n",
    "      <li><a href=\"#visualize-data\">Visualize the Data</a></li>\n",
    "      <li><a href=\"#draw-images\">Draw Images</a></li>\n",
    "      <li><a href=\"#correlation-analysis\">Correlation Analysis</a></li>\n",
    "      <li><a href=\"#divide-data\">Divide the Data</a></li>\n",
    "      <li><a href=\"#standardize-data\">Standardize the Data</a></li>\n",
    "      <li><a href=\"#encode-labels\">Encode the Labels</a></li>\n",
    "    </ol>\n",
    "  </li>\n",
    "  <li><a href=\"#part-ii\">Part II: Training a Neural Network (CNN)</a>\n",
    "    <ol>\n",
    "      <li><a href=\"#implement-a-cnn-model\">Implement a CNN Model</a></li>\n",
    "      <li><a href=\"#write-training-function\">Write Training Function</a></li>\n",
    "      <li><a href=\"#explore-hyperparameter-settings\">Explore Hyperparameter Settings</a></li>\n",
    "      <li><a href=\"#tensorboard-monitoring\">TensorBoard Monitoring</a></li>\n",
    "      <li><a href=\"#evaluation-function\">Evaluation Function</a></li>\n",
    "    </ol>\n",
    "  </li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Description</h3>\n",
    "<a id=\"description\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First lets write our imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Part I: Data Preparation\n",
    "<a id=\"part-i\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Taking a look and Describing the data</h2>\n",
    "<a id=\"describe-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training set\n",
    "train_df = pd.read_csv(r'.\\data_files\\train.csv')\n",
    "\n",
    "print(\"#-----> First 5 rows of the training set:\\n\")\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----> training set description:\")\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----> training set information\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----> training set value types\")\n",
    "train_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the testing set\n",
    "test_df = pd.read_csv(r'.\\data_files\\test.csv')\n",
    "\n",
    "print(\"#-----> First 5 rows of the testing set:\")\n",
    "test_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----> testing set description:\")\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----> testing set information\")\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----> testing set value types\")\n",
    "test_df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cleaning the data</h2>\n",
    "<a id=\"clean-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the data for missing values or duplicates and carrying out proper correction methods\n",
    "<a id=\"check-values\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", train_df.isnull().sum(), \"\\n\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"Duplicate values:\\n\", train_df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----> Looks like we don't have any missing or duplicate values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue lets setup our data by dropping the the id and species from the features and set the target on species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'id' and 'species' columns\n",
    "X_features = train_df.drop(['id', 'species'], axis=1)\n",
    "y_target = train_df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data\n",
    "<a id=\"viualize-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Distributions\n",
    "\n",
    "features = train_df.iloc[:, 1:]  # Assuming features start from column 2\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# for i, feature in enumerate(features.columns, 1):\n",
    "#     plt.subplot(3, 3, i)\n",
    "#     sns.histplot(train_df[feature], kde=True)\n",
    "#     plt.title(f'Distribution of {feature}')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# features = train_df.iloc[:, 1:]\n",
    "# plt.figure(figsize=(12, 3 * features.shape[1]))  # Adjust the figure height based on the number of features\n",
    "# for i, feature in enumerate(features.columns, 1):\n",
    "#     plt.subplot(features.shape[1], 1, i)\n",
    "#     sns.histplot(train_df[feature], kde=True)\n",
    "#     plt.title(f'Distribution of {feature}')\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Visualization 3: Pairwise Feature Scatter Plots\n",
    "# sns.pairplot(train_df.sample(IMAGE_SIZE), hue='species', diag_kind='kde')\n",
    "# plt.suptitle('Pairwise Scatter Plots for Features', y=1.02)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensionality Reduction Visualization (using PCA)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(X_features)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=pca_result[:, 0], y=pca_result[:, 1], hue=train_df['species'])\n",
    "plt.title('PCA Visualization')\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "image_dir = '.\\data_files\\images'\n",
    "image_ids = train_df['id'].head(5).tolist() \n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "for layer_number, image_id in enumerate(image_ids, 1):\n",
    "    image_path = os.path.join(image_dir, f\"{image_id}.jpg\")\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "    plt.subplot(1, 5, layer_number)\n",
    "    plt.imshow(image)\n",
    "    plt.title(f\"Image {layer_number}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Correlation Analysis </h2>\n",
    "<a id=\"correlation-analysis\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we are going to calculate the correlation matrix for shape features<br>\n",
    "we will use heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix and Distribution for Each Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming features are grouped into margin, shape, and texture\n",
    "margin_features = X_features.iloc[:, :64]\n",
    "shape_features = X_features.iloc[:, 64:128]\n",
    "texture_features = X_features.iloc[:, 128:]\n",
    "\n",
    "feature_groups = [margin_features, shape_features, texture_features]\n",
    "group_names = ['Margin Features', 'Shape Features', 'Texture Features']\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(18, 16))\n",
    "fig.suptitle('Analysis of Feature Groups')\n",
    "\n",
    "\n",
    "# Flatten the 2D array of subplots for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "for layer_number, features in enumerate(feature_groups):\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = features.corr()\n",
    "\n",
    "    # Plot correlation heatmap\n",
    "    sns.heatmap(correlation_matrix, cmap='coolwarm', ax=axes[layer_number * 2])\n",
    "    axes[layer_number * 2].set_title(f'Correlation Matrix - {group_names[layer_number]}')\n",
    "\n",
    "    # Plot distribution for the first feature in the group\n",
    "    sns.histplot(data=features, x=features.columns[0], kde=True, ax=axes[layer_number * 2 + 1])\n",
    "    axes[layer_number * 2 + 1].set_title(f'Distribution - {group_names[layer_number]}')\n",
    "\n",
    "# Adjust layout to prevent overlapping\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deciding which split method to use\n",
    "<a id=\"divide-data\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We got two methods for splitting:\n",
    "<ol>\n",
    "<li>train_test_split</li>\n",
    "<li>StratifiedShuffleSplit (sss)</li>\n",
    "</ol>\n",
    "\n",
    "<b>train_test_split:</b></br>\n",
    "Usage: Commonly used for general train-test splitting, especially when the class distribution is not a significant concern.<br>\n",
    "How it works: Randomly shuffles and splits the data into training and test sets.<br>\n",
    "Advantage: Simplicity and ease of use. Suitable for well-balanced datasets.<br>\n",
    "\n",
    "<b>StratifiedShuffleSplit:</b></br>\n",
    "Usage: Typically used when you want to ensure that the distribution of classes in both the training and validation sets is representative of the overall distribution in the dataset.<br>\n",
    "How it works: StratifiedShuffleSplit maintains the class distribution when creating random splits. It shuffles the data and then creates splits, ensuring that each split has a similar class distribution.<br>\n",
    "Advantage: Useful when dealing with imbalanced datasets where certain classes have significantly fewer samples than others.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the dataset has a <b>balanced</b> class distribution, and just need a simple split, train_test_split is often sufficient and easier to use.<br>\n",
    "\n",
    "If the dataset has <b>imbalanced</b> classes, and want to ensure that the class distribution is maintained in both training and validation sets, then StratifiedShuffleSplit is a good choice.<br>\n",
    "\n",
    "To decide which approach is better the dataset, we can can check the distribution of the 'species' column in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 6))\n",
    "sns.countplot(x='species', data=train_df)\n",
    "plt.title('Distribution of Leaf Classes')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----> since all the bars are the same height that means its balanced and we can use the regular train_test_split method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'id' and 'species' columns\n",
    "X_features = train_df.drop(['species'], axis=1)\n",
    "# y_target = train_df['species']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Train/Test split</h2>\n",
    "Divide the data into a training and testing set using approximately 80% for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_size = 0.2 meaning that the training set will be 0.8 (80%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Standardization</h2>\n",
    "<a id=\"standardize-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Label Encoding</h2>\n",
    "<a id=\"encode-labels\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# read image\n",
    "img = cv2.imread('data_files/images/1.jpg')\n",
    "color = (0,0,0)\n",
    "result = img.copy()\n",
    "result = cv2.copyMakeBorder(result, 0,0,90,90, cv2.BORDER_CONSTANT, value=color)\n",
    "\n",
    "plt.figure(figsize=(24, 16))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(img)\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import zipfile\n",
    "# with zipfile.ZipFile('/data_files/images/leaf-classification/images.zip') as z_img:\n",
    "#     z_img.extractall()\n",
    "from PIL import Image, ImageOps\n",
    "import glob\n",
    "# image_list = []\n",
    "\n",
    "def resize_img(img):\n",
    "     # height, width, number of channels in image\n",
    "    height = img.shape[0]\n",
    "    width = img.shape[1]\n",
    "    diff = int(abs(width-height)/2)\n",
    "    color = (0,0,0)\n",
    "    result = img.copy()\n",
    "    if width<height:\n",
    "        result = cv2.copyMakeBorder(result, 0,0,diff,diff, cv2.BORDER_CONSTANT, value=color)\n",
    "    elif height>width:\n",
    "        result = cv2.copyMakeBorder(result, diff,diff,0,0, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "    # resize images\n",
    "    result = cv2.resize(result, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    # resize images\n",
    "#     result = cv2.resize(result, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "# for filename in glob.glob('data_files/images/*.jpg'): #assuming jpg\n",
    "#     # im=Image.open(filename)\n",
    "#     img = cv2.imread(filename)\n",
    "#     dimensions = img.shape\n",
    " \n",
    "#     # height, width, number of channels in image\n",
    "#     height = img.shape[0]\n",
    "#     width = img.shape[1]\n",
    "#     diff = int(abs(width-height)/2)\n",
    "#     color = (0,0,0)\n",
    "#     result = img.copy()\n",
    "#     if width<height:\n",
    "#         result = cv2.copyMakeBorder(result, 0,0,diff,diff, cv2.BORDER_CONSTANT, value=color)\n",
    "#     elif height>width:\n",
    "#         result = cv2.copyMakeBorder(result, diff,diff,0,0, cv2.BORDER_CONSTANT, value=color)\n",
    "    \n",
    "#     # resize images\n",
    "#     result = cv2.resize(result, (IMAGE_SIZE,IMAGE_SIZE))\n",
    "#     image_list.append(result)\n",
    "    \n",
    "# plt.figure(figsize=(24, 16))\n",
    "# for i in range(25):\n",
    "#     # j=np.random.choice((os.listdir('images')))\n",
    "#     plt.subplot(5,5,i+1)\n",
    "#     # img=load_img(os.path.join('/kaggle/working/images',j))\n",
    "#     img = image_list[i]\n",
    "#     plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Part II: Training the Neural Network</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "def load_img_data(data):\n",
    "    data_ID = data['id']\n",
    "\n",
    "    X = np.empty((len(data_ID), IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "    for i, idnum in enumerate(data_ID):\n",
    "        x = cv2.imread((\"data_files/images/\" + str(idnum) + '.jpg'), cv2.IMREAD_GRAYSCALE)\n",
    "        # x = image.load_img(\n",
    "        #     (\"data_files/images/\" + str(idnum) + '.jpg'), grayscale=True)\n",
    "        x = image.img_to_array(resize_img(x))\n",
    "        X[i] = x\n",
    "\n",
    "    return np.around(X / 255.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.preprocessing import image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Conv2D, MaxPooling2D, Flatten, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveCovNet(input_layer):\n",
    "    conv_layers = 4\n",
    "    BASE_CONV_FILTERS = 8\n",
    "    x = input_layer\n",
    "    for _ in range(conv_layers):\n",
    "        x = Conv2D(BASE_CONV_FILTERS, 5, padding='same')(x)\n",
    "        x = (Activation('relu'))(x)\n",
    "        x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "        BASE_CONV_FILTERS*=2\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, kernel_initializer='glorot_normal', activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(99, kernel_initializer='glorot_normal', activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    output_layer = Dense(99, activation='softmax')(x)\n",
    "    model = Model(input_layer, output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(792, 128, 128, 1)\n",
      "(792,)\n"
     ]
    }
   ],
   "source": [
    "trian_X = load_img_data(X_train)\n",
    "train_y = y_train_encoded\n",
    "print(trian_X.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "<tf.Variable 'learning_rate:0' shape=() dtype=float32, numpy=0.9>\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_58 (Conv2D)          (None, 128, 128, 8)       208       \n",
      "                                                                 \n",
      " activation_58 (Activation)  (None, 128, 128, 8)       0         \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPooli  (None, 64, 64, 8)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_59 (Conv2D)          (None, 64, 64, 16)        3216      \n",
      "                                                                 \n",
      " activation_59 (Activation)  (None, 64, 64, 16)        0         \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPooli  (None, 32, 32, 16)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 32, 32, 32)        12832     \n",
      "                                                                 \n",
      " activation_60 (Activation)  (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPooli  (None, 16, 16, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 16, 16, 64)        51264     \n",
      "                                                                 \n",
      " activation_61 (Activation)  (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPooli  (None, 8, 8, 64)          0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 2048)              8390656   \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 99)                202851    \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 99)                0         \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 99)                9900      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8670927 (33.08 MB)\n",
      "Trainable params: 8670927 (33.08 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1), name='image')\n",
    "model = NaiveCovNet(input_layer)\n",
    "optimizer = keras.optimizers.Adam()\n",
    "# print(optimizer.learning_rate)\n",
    "# optimizer.learning_rate = 0.9\n",
    "# print(optimizer.learning_rate)\n",
    "model.compile(optimizer=\"Adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "7/7 [==============================] - 2s 142ms/step - loss: 4.5956 - accuracy: 0.0088\n",
      "Epoch 2/40\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 4.5220 - accuracy: 0.0303\n",
      "Epoch 3/40\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 4.1628 - accuracy: 0.0720\n",
      "Epoch 4/40\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 3.8209 - accuracy: 0.1199\n",
      "Epoch 5/40\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 3.4876 - accuracy: 0.1503\n",
      "Epoch 6/40\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 2.9780 - accuracy: 0.2652\n",
      "Epoch 7/40\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 2.6326 - accuracy: 0.3295\n",
      "Epoch 8/40\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 2.3009 - accuracy: 0.3952\n",
      "Epoch 9/40\n",
      "7/7 [==============================] - 1s 146ms/step - loss: 1.9042 - accuracy: 0.4735\n",
      "Epoch 10/40\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 1.7879 - accuracy: 0.4912\n",
      "Epoch 11/40\n",
      "7/7 [==============================] - 1s 143ms/step - loss: 1.5363 - accuracy: 0.5720\n",
      "Epoch 12/40\n",
      "7/7 [==============================] - 1s 141ms/step - loss: 1.3284 - accuracy: 0.6212\n",
      "Epoch 13/40\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 1.2148 - accuracy: 0.6439\n",
      "Epoch 14/40\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 0.9574 - accuracy: 0.7083\n",
      "Epoch 15/40\n",
      "7/7 [==============================] - 1s 141ms/step - loss: 0.9455 - accuracy: 0.7058\n",
      "Epoch 16/40\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 0.8206 - accuracy: 0.7790\n",
      "Epoch 17/40\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 0.7069 - accuracy: 0.7765\n",
      "Epoch 18/40\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.6827 - accuracy: 0.7942\n",
      "Epoch 19/40\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 0.6078 - accuracy: 0.8270\n",
      "Epoch 20/40\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 0.4908 - accuracy: 0.8283\n",
      "Epoch 21/40\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 0.4460 - accuracy: 0.8485\n",
      "Epoch 22/40\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.3956 - accuracy: 0.8687\n",
      "Epoch 23/40\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 0.3386 - accuracy: 0.8864\n",
      "Epoch 24/40\n",
      "7/7 [==============================] - 1s 141ms/step - loss: 0.2790 - accuracy: 0.9116\n",
      "Epoch 25/40\n",
      "7/7 [==============================] - 1s 139ms/step - loss: 0.2612 - accuracy: 0.9179\n",
      "Epoch 26/40\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 0.2674 - accuracy: 0.9192\n",
      "Epoch 27/40\n",
      "7/7 [==============================] - 1s 142ms/step - loss: 0.2611 - accuracy: 0.9192\n",
      "Epoch 28/40\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 0.2498 - accuracy: 0.9192\n",
      "Epoch 29/40\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.2409 - accuracy: 0.9343\n",
      "Epoch 30/40\n",
      "7/7 [==============================] - 1s 145ms/step - loss: 0.1810 - accuracy: 0.9508\n",
      "Epoch 31/40\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.1450 - accuracy: 0.9520\n",
      "Epoch 32/40\n",
      "7/7 [==============================] - 1s 144ms/step - loss: 0.1517 - accuracy: 0.9520\n",
      "Epoch 33/40\n",
      "7/7 [==============================] - 1s 140ms/step - loss: 0.1064 - accuracy: 0.9747\n",
      "Epoch 34/40\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.0700 - accuracy: 0.9760\n",
      "Epoch 35/40\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 0.0718 - accuracy: 0.9785\n",
      "Epoch 36/40\n",
      "7/7 [==============================] - 1s 138ms/step - loss: 0.1031 - accuracy: 0.9684\n",
      "Epoch 37/40\n",
      "7/7 [==============================] - 1s 149ms/step - loss: 0.0941 - accuracy: 0.9684\n",
      "Epoch 38/40\n",
      "7/7 [==============================] - 1s 153ms/step - loss: 0.1120 - accuracy: 0.9710\n",
      "Epoch 39/40\n",
      "7/7 [==============================] - 1s 147ms/step - loss: 0.1243 - accuracy: 0.9609\n",
      "Epoch 40/40\n",
      "7/7 [==============================] - 1s 148ms/step - loss: 0.1287 - accuracy: 0.9596\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"logs/{}\".format(time.time()))\n",
    "history = model.fit(trian_X, train_y, epochs=40, batch_size=128, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizes = [64,128,256]\n",
    "number_of_layers = [1,2,3,4,5]\n",
    "dropout_rates = [0.2,0.3,0.4,0.5,0.6]\n",
    "optimizers = [keras.optimizers.Adam,keras.optimizers.SGD,keras.optimizers.RMSprop,keras.optimizers.Adagrad]\n",
    "weight_decays = [0.0001,0.001,0.01,0.05,0.1]\n",
    "learning_rates = [0.0005,0.001,0.005,0.01]\n",
    "learning_rate_schedulers = [\n",
    "    None,\n",
    "    keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.01,decay_steps=1000,decay_rate=0.9),\n",
    "    keras.optimizers.schedules.InverseTimeDecay(initial_learning_rate=0.01,decay_steps=1000,decay_rate=0.9),\n",
    "    keras.optimizers.schedules.CosineDecay(initial_learning_rate=0.01,decay_steps=1000),\n",
    "    keras.optimizers.schedules.PolynomialDecay(initial_learning_rate=0.01,decay_steps=1000)\n",
    "    ]\n",
    "\n",
    "# default\n",
    "default_batch_size = 128\n",
    "default_number_of_layers = 3\n",
    "default_dropout_rate = 0.5\n",
    "default_optimizer = keras.optimizers.Adam\n",
    "default_weight_decay = 0.01\n",
    "default_learning_rate = 0.001\n",
    "default_learning_rate_scheduler = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateModel(batch_size,number_of_layers,dropout_rate,optimizer,weight_decay,learning_rate,learning_rate_scheduler):\n",
    "    input_layer = Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 1), name='image')\n",
    "    kernel_regularizer=keras.regularizers.L2(l2=weight_decay)\n",
    "    def NaiveCovNet():\n",
    "        BASE_CONV_FILTERS = 8\n",
    "        x = input_layer\n",
    "        for _ in range(number_of_layers):\n",
    "            x = Conv2D(BASE_CONV_FILTERS, 5, padding='same')(x)\n",
    "            x = (Activation('relu'))(x)\n",
    "            x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "            BASE_CONV_FILTERS*=2\n",
    "\n",
    "        # Flatten our array\n",
    "        x = Flatten()(x)\n",
    "        x = Dense(2048, kernel_initializer='glorot_normal', activation='relu')(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        x = Dense(99, kernel_initializer='glorot_normal', activation='relu')(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "\n",
    "        output_layer = Dense(99, activation='softmax')(x)\n",
    "        model = Model(input_layer, output_layer)\n",
    "        return model\n",
    "\n",
    "\n",
    "    model = NaiveCovNet()\n",
    "    # print(optimizer.learning_rate)\n",
    "    # optimizer.learning_rate = 0.9\n",
    "    # print(optimizer.learning_rate)\n",
    "    optimizer = optimizer()\n",
    "    learning_rate_scheduler_name = str(learning_rate_scheduler.__class__).split(\".\")[-1]\n",
    "    if learning_rate_scheduler is None:\n",
    "        optimizer.learning_rate = learning_rate\n",
    "        learning_rate_scheduler_name = \"fixed\"\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "\n",
    "    optimizer_name = str(optimizer.__class__).split(\".\")[-1][:-2]\n",
    "    \n",
    "    hyperparameters = [batch_size,number_of_layers,dropout_rate,optimizer_name,weight_decay,learning_rate,learning_rate_scheduler_name]\n",
    "\n",
    "    def getLogName():\n",
    "        return \" \".join([str(x) for x in hyperparameters])\n",
    "    \n",
    "    print(getLogName())\n",
    "        \n",
    "    tensorboard_callback = keras.callbacks.TensorBoard(log_dir=\"logs/{}/{}\".format(getLogName(),time.time()))\n",
    "    history = model.fit(trian_X, train_y, epochs=40, batch_size=batch_size, callbacks=[tensorboard_callback])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 128, 128, 1)\n",
      "(198,)\n",
      "7/7 [==============================] - 0s 19ms/step - loss: 1.1476 - accuracy: 0.7323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.147599220275879, 0.7323232293128967]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = load_img_data(X_test)\n",
    "test_y = y_test_encoded\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n",
    "model.evaluate(test_X, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_47\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " image (InputLayer)          [(None, 128, 128, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 128, 128, 8)       208       \n",
      "                                                                 \n",
      " activation_137 (Activation  (None, 128, 128, 8)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling2d_130 (MaxPool  (None, 64, 64, 8)         0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_138 (Conv2D)         (None, 64, 64, 16)        3216      \n",
      "                                                                 \n",
      " activation_138 (Activation  (None, 64, 64, 16)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling2d_131 (MaxPool  (None, 32, 32, 16)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         (None, 32, 32, 32)        12832     \n",
      "                                                                 \n",
      " activation_139 (Activation  (None, 32, 32, 32)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " max_pooling2d_132 (MaxPool  (None, 16, 16, 32)        0         \n",
      " ing2D)                                                          \n",
      "                                                                 \n",
      " flatten_47 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 2048)              16779264  \n",
      "                                                                 \n",
      " dropout_92 (Dropout)        (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 99)                202851    \n",
      "                                                                 \n",
      " dropout_93 (Dropout)        (None, 99)                0         \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 99)                9900      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17008271 (64.88 MB)\n",
      "Trainable params: 17008271 (64.88 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "128 3 0.5 Adam 0.01 0.001 fixed\n",
      "Epoch 1/40\n",
      "7/7 [==============================] - 3s 186ms/step - loss: 4.6401 - accuracy: 0.0114\n",
      "Epoch 2/40\n",
      "7/7 [==============================] - 1s 198ms/step - loss: 4.5627 - accuracy: 0.0126\n",
      "Epoch 3/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 4.4531 - accuracy: 0.0417\n",
      "Epoch 4/40\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 4.2079 - accuracy: 0.0745\n",
      "Epoch 5/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 3.9839 - accuracy: 0.1199\n",
      "Epoch 6/40\n",
      "7/7 [==============================] - 1s 204ms/step - loss: 3.8320 - accuracy: 0.1035\n",
      "Epoch 7/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 3.5826 - accuracy: 0.1616\n",
      "Epoch 8/40\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 3.2305 - accuracy: 0.2159\n",
      "Epoch 9/40\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 3.0313 - accuracy: 0.2677\n",
      "Epoch 10/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 2.6927 - accuracy: 0.3333\n",
      "Epoch 11/40\n",
      "7/7 [==============================] - 1s 183ms/step - loss: 2.4886 - accuracy: 0.3674\n",
      "Epoch 12/40\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 2.3795 - accuracy: 0.3838\n",
      "Epoch 13/40\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 2.2277 - accuracy: 0.4167\n",
      "Epoch 14/40\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 1.9571 - accuracy: 0.4798\n",
      "Epoch 15/40\n",
      "7/7 [==============================] - 1s 190ms/step - loss: 1.7562 - accuracy: 0.5177\n",
      "Epoch 16/40\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 1.6330 - accuracy: 0.5556\n",
      "Epoch 17/40\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 1.5123 - accuracy: 0.5846\n",
      "Epoch 18/40\n",
      "7/7 [==============================] - 1s 195ms/step - loss: 1.4601 - accuracy: 0.5934\n",
      "Epoch 19/40\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 1.3550 - accuracy: 0.6212\n",
      "Epoch 20/40\n",
      "7/7 [==============================] - 1s 202ms/step - loss: 1.2152 - accuracy: 0.6427\n",
      "Epoch 21/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 1.1863 - accuracy: 0.6566\n",
      "Epoch 22/40\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 1.0236 - accuracy: 0.7109\n",
      "Epoch 23/40\n",
      "7/7 [==============================] - 1s 185ms/step - loss: 1.0213 - accuracy: 0.6957\n",
      "Epoch 24/40\n",
      "7/7 [==============================] - 1s 199ms/step - loss: 0.8521 - accuracy: 0.7260\n",
      "Epoch 25/40\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.7857 - accuracy: 0.7639\n",
      "Epoch 26/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.7493 - accuracy: 0.7626\n",
      "Epoch 27/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.7405 - accuracy: 0.7740\n",
      "Epoch 28/40\n",
      "7/7 [==============================] - 1s 193ms/step - loss: 0.6330 - accuracy: 0.7980\n",
      "Epoch 29/40\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.5966 - accuracy: 0.8093\n",
      "Epoch 30/40\n",
      "7/7 [==============================] - 1s 200ms/step - loss: 0.5872 - accuracy: 0.8258\n",
      "Epoch 31/40\n",
      "7/7 [==============================] - 1s 191ms/step - loss: 0.5808 - accuracy: 0.8131\n",
      "Epoch 32/40\n",
      "7/7 [==============================] - 1s 189ms/step - loss: 0.5448 - accuracy: 0.8359\n",
      "Epoch 33/40\n",
      "7/7 [==============================] - 1s 188ms/step - loss: 0.4973 - accuracy: 0.8510\n",
      "Epoch 34/40\n",
      "7/7 [==============================] - 1s 194ms/step - loss: 0.4449 - accuracy: 0.8674\n",
      "Epoch 35/40\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.4305 - accuracy: 0.8586\n",
      "Epoch 36/40\n",
      "7/7 [==============================] - 1s 187ms/step - loss: 0.3879 - accuracy: 0.8763\n",
      "Epoch 37/40\n",
      "7/7 [==============================] - 1s 186ms/step - loss: 0.4012 - accuracy: 0.8826\n",
      "Epoch 38/40\n",
      "7/7 [==============================] - 1s 196ms/step - loss: 0.4199 - accuracy: 0.8586\n",
      "Epoch 39/40\n",
      "7/7 [==============================] - 1s 182ms/step - loss: 0.3426 - accuracy: 0.8838\n",
      "Epoch 40/40\n",
      "7/7 [==============================] - 1s 184ms/step - loss: 0.3455 - accuracy: 0.8952\n"
     ]
    }
   ],
   "source": [
    "model = generateModel(default_batch_size,default_number_of_layers,default_dropout_rate,default_optimizer,default_weight_decay,default_learning_rate,default_learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(198, 128, 128, 1)\n",
      "(198,)\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 1.3209 - accuracy: 0.7071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3209306001663208, 0.7070707082748413]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = load_img_data(X_test)\n",
    "test_y = y_test_encoded\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n",
    "model.evaluate(test_X, test_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
